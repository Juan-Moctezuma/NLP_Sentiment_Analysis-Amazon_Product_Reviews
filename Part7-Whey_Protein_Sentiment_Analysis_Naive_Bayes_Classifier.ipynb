{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "389659cf",
   "metadata": {},
   "source": [
    "# NLP - Sentiment Analysis for Amazon Product Reviews\n",
    "# Naive Bayes Classifier - based on Bayes' Probability Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2410fe3b",
   "metadata": {},
   "source": [
    "In this notebook we will not be doing sentiment analysis based on a corpus of text, but we'll apply Naive Bayes' statistical method to calculate the probability of customers liking current whey protein products from Amazon. This method classify whether consumers will provide a positive comment or a negative review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6db06d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "# Libraries for Naive Bayes\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from mlxtend.plotting import plot_decision_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6033ffdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read scraped results from CSV\n",
    "df = pd.read_csv('Whey_Protein_Amazon_Preprocessed_Reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdc0a29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change data type for 'Review' to 'string' & fill empty cells (from CSV) with NA\n",
    "df['Reviews'] = df['Reviews'].astype('string')\n",
    "df = df.fillna('NA')\n",
    "# Drop extra unnamed column\n",
    "#col_0 = df.columns[0]\n",
    "#df.drop(col_0, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9002439",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m nltk.downloader stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68424657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                int64\n",
      "Product_Name     object\n",
      "Date             object\n",
      "Rating_Score    float64\n",
      "Reviews          string\n",
      "Link             object\n",
      "Product_ID       object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ea6920",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25e696ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tfidf Vectorizer\n",
    "stopset= set(stopwords.words('english'))\n",
    "vectorizer= TfidfVectorizer(use_idf = True, \\\n",
    "                            lowercase = True, \\\n",
    "                            token_pattern = '[a-zA-Z.0-9+#-/]*[^.\\s]', \\\n",
    "                            strip_accents = 'ascii', \\\n",
    "                            stop_words = stopset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "944d0435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A) We assign new column with values of 'one' to 3, 4 & 5 star-comments, and a 'zero' to 1 & 2 star-comments\n",
    "# B) We assign new column with values of 'one' to 4 & 5 star-comments, and a 'zero' to 1, 2 & 3 star-comments\n",
    "df['sentiments'] = df['Rating_Score'].apply(lambda x: 0 if x in [1, 2] else 1)\n",
    "#df['sentiments'] = df['Rating_Score'].apply(lambda x: 0 if x in [1, 2, 3] else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "565e8d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this case our dependant variable will be 'sentiments' as 0 (didn't liket) \n",
    "# OR 1 (did like the product or are neutral)\n",
    "y = df.sentiments.values\n",
    "X = df.Reviews.values\n",
    "encoder = LabelEncoder()\n",
    "encoded_labels = encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "baebec98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We split the data into 80% train and 20% test parts\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, encoded_labels, stratify = encoded_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2448b7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We store words in a dictionary called ‘word_counts’. All the unique words in the corpus are stored in ‘vocab’\n",
    "vec = CountVectorizer(max_features = 3000)\n",
    "X_trained = vec.fit_transform(X_train)\n",
    "vocab = vec.get_feature_names_out()\n",
    "X_trained = X_trained.toarray()\n",
    "word_counts = {}\n",
    "for l in range(2):\n",
    "    word_counts[l] = defaultdict(lambda: 0)\n",
    "for i in range(X_trained.shape[0]):\n",
    "    l = y_train[i]\n",
    "    for j in range(len(vocab)):\n",
    "        word_counts[l][vocab[j]] += X_trained[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1c6b2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to perform Laplace smoothing to handle words in the test set which are absent in the training set. \n",
    "# We define a function ‘laplace_smoothing’ which takes the vocabulary and the raw ‘word_counts’ dictionary and \n",
    "# returns the smoothened conditional probabilities.\n",
    "def laplace_smoothing(n_label_items, vocab, word_counts, word, text_label):\n",
    "    a = word_counts[text_label][word] + 1\n",
    "    b = n_label_items[text_label] + len(vocab)\n",
    "    return math.log(a/b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b15ed630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define the ‘fit’ and ‘predict’ functions for our classifier\n",
    "def group_by_label(x, y, labels):\n",
    "    data = {}\n",
    "    for l in labels:\n",
    "        data[l] = x[np.where(y == l)]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78e7b062",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(x, y, labels):\n",
    "    n_label_items = {}\n",
    "    log_label_priors = {}\n",
    "    n = len(x)\n",
    "    grouped_data = group_by_label(x, y, labels)\n",
    "    for l, data in grouped_data.items():\n",
    "        n_label_items[l] = len(data)\n",
    "        log_label_priors[l] = math.log(n_label_items[l] / n)\n",
    "    return n_label_items, log_label_priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87244e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m nltk.downloader punkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89308c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(n_label_items, vocab, word_counts, log_label_priors, labels, x):\n",
    "    result = []\n",
    "    for text in x:\n",
    "        label_scores = {l: log_label_priors[l] for l in labels}\n",
    "        words = set(sent_tokenize(text))\n",
    "        for word in words:\n",
    "            if word not in vocab: continue\n",
    "            for l in labels:\n",
    "                log_w_given_l = laplace_smoothing(n_label_items, vocab, word_counts, word, l)\n",
    "                label_scores[l] += log_w_given_l\n",
    "        result.append(max(label_scores, key = label_scores.get))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc039397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of prediction on test set :  0.9445114595898673\n"
     ]
    }
   ],
   "source": [
    "labels = [0,1]\n",
    "n_label_items, log_label_priors = fit(X_train, y_train, labels)\n",
    "pred = predict(n_label_items, vocab, word_counts, log_label_priors, labels, X_test)\n",
    "print(\"Accuracy of prediction on test set : \", accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8225ea9c",
   "metadata": {},
   "source": [
    "# Conclusion 1 - Case when out hypothesis states that 3-star ratings are biased towards ‘positive’ sentiment: The classifier is now fitted on the X_train and is used to predict labels for the X_test. The accuracy of the positive sentiment prediction on the test set comes out to be 94.45%, which is excellent! This means that the probability of a customer liking current available whey protein products is 94.5%. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e93fbc0",
   "metadata": {},
   "source": [
    "# Conclusion 2 - Case when out hypothesis states that 3-star ratings are biased towards ‘negative’ sentiment: The classifier is now fitted on the X_train and is used to predict labels for the X_test. The accuracy of the positive sentiment prediction on the test set comes out to be 85.65%. This means that the probability of a customer liking current available whey protein products decreases 8.8% according to this model/classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b968c849",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
